# -*- coding: utf-8 -*-
"""ModelV04.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WnM6hEjCMwJrZc5yJzeGqPZm0MEIaNjz

##**Import Packages**
"""

import tensorflow as tf
from tensorflow import keras
tf.config.run_functions_eagerly(True)
import numpy as np
import pandas as pd
import sklearn
import pickle
from sklearn import preprocessing
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

"""##**Import Data & Labelling**"""

import pandas as pd

url_data = 'https://raw.githubusercontent.com/zakkutachibana/FoodMoodFinderCapstone/main/Machine%20Learning/dataset/dataset.csv'
data = pd.read_csv(url_data)

print(data)

#from google.colab import drive
#drive.mount('/content/drive')

#import dataset_capstone.csv
#data = pd.read_csv("/content/drive/MyDrive/Capstone/dataset_capstone.csv")

data

data.shape

data.isna().sum()

#data = data.dropna()

import pandas as pd

url_class = 'https://raw.githubusercontent.com/zakkutachibana/FoodMoodFinderCapstone/main/Machine%20Learning/dataset/class_1.1.0.csv'
list_class = pd.read_csv(url_class)

print(list_class)

#inner join based on the same column
data = pd.merge(data, list_class, on=['Karbohidrat', 'Protein', 'Sayur', 'Pengolahan'], how='inner')

#merge class values according to the first dataset
data['Kelas'] = data['Kelas_x']

#display only the columns 'Karbohidrat', 'Protein', 'Sayur', 'Pengolahan', dan 'Kelas'
data = data[['Makanan','Karbohidrat', 'Protein', 'Sayur', 'Pengolahan', 'Kelas']]

#display the merge result with the merged class values
print(data)

data.isna().sum()

import pandas as pd

url_image = 'https://raw.githubusercontent.com/zakkutachibana/FoodMoodFinderCapstone/main/Machine%20Learning/dataset/image_dataset.csv'
image = pd.read_csv(url_image)

print(image)

#inner join based on the same column
data = pd.merge(data, image, on=['Makanan'], how='inner')

#merge class values according to the first dataset
data['Gambar'] = data['Gambar']

#display only the columns 'Karbohidrat', 'Protein', 'Sayur', 'Pengolahan', dan 'Kelas'
data = data[['Makanan','Karbohidrat', 'Protein', 'Sayur', 'Pengolahan', 'Kelas','Gambar']]

#display the merge result with the merged class values
print(data)

data

#from google.colab import drive
#drive.mount('/content/drive')

data.to_csv('final_dataset.csv')

#data.to_csv('/content/drive/MyDrive/Capstone/final_dataset.csv')

data

from sklearn.preprocessing import LabelEncoder

#create instance of label encoder
label_encoder = LabelEncoder()

#perform label encoding on 'team' column
data['Karbohidrat'] = label_encoder.fit_transform(data['Karbohidrat'])
data['Protein'] = label_encoder.fit_transform(data['Protein'])
data['Sayur'] = label_encoder.fit_transform(data['Sayur'])
data['Pengolahan'] = label_encoder.fit_transform(data['Pengolahan'])

data

"""*Karbohidrat*


*  0 = Beras dan olahannya
*  1 = Lainnya
*  2 = Tepung, Mie, dan Pasta
*  3 = Tidak ada

*Protein*


*  0 = Ayam dan daging
*  1 = Ikan dan Seafood
*  2 = Lainnya
*  3 = Tahu, tempe, dan telur
*  4 = Tidak ada

*Sayur*


*  0 = Tidak
*  1 = Ya

*Pengolahan*


*  0 = Goreng atau tumis
*  1 = Lainnya
*  2 = Panggang atau bakar
*  3 = Rebus atau kukus

##**Label and Split Data**
"""

df = data[["Karbohidrat",  "Protein", "Sayur", "Pengolahan","Kelas"]]

from sklearn.model_selection import train_test_split

# Memisahkan dataset menjadi train_df dan sisanya
train_df, remaining_df = train_test_split(df, test_size=0.2)

# Memisahkan sisanya menjadi test_df dan val_df
test_df, val_df = train_test_split(remaining_df, test_size=0.5)

train_df

test_df

val_df

#form np arrays of labels and features.
train_labels = np.array(train_df.pop('Kelas'))
bool_train_labels = train_labels != 0
val_labels = np.array(val_df.pop('Kelas'))
test_labels = np.array(test_df.pop('Kelas'))

train_features = np.array(train_df)
val_features = np.array(val_df)
test_features = np.array(test_df)

print('Training labels shape:', train_labels.shape)
print('Validation labels shape:', val_labels.shape)
print('Test labels shape:', test_labels.shape)

print('Training features shape:', train_features.shape)
print('Validation features shape:', val_features.shape)
print('Test features shape:', test_features.shape)

train_features

test_features

val_features

train_labels

val_labels

test_labels

"""##**Model**"""

model = tf.keras.Sequential([
    tf.keras.layers.Dense(512, activation='relu', input_shape=(4,)),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(125, activation='relu'),
    tf.keras.layers.Dense(125, activation='relu'),
    tf.keras.layers.Dense(24, activation='softmax')
])

model.compile(optimizer='adam', loss="SparseCategoricalCrossentropy" , metrics=['accuracy'])

model.summary()

#setting Callbacks

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.995):
      print("\nReached 99.5% accuracy so cancelling training!")
      self.model.stop_training = True

callbacks = myCallback()

epochs=300
history = model.fit(train_features,
                    train_labels,
                    epochs=epochs,
                    callbacks = [callbacks],
                    validation_data = (val_features, val_labels))

#plotting accuracy and loss
import matplotlib.pyplot as plt
acc = history.history['accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
val_acc = history.history['val_accuracy']

epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Acccuracy')
plt.legend()

plt.figure()
plt.plot(epochs, loss, 'b', label='Training Loss')
plt.plot(epochs, val_loss, 'r', label='Validation Loss')
plt.title('Loss')
plt.legend()

plt.show()

# Simpan model ke dalam file
model.save("model.h5")

from tensorflow.keras.models import load_model

#load a model from a file
loaded_model = load_model("model.h5")

#evaluation of loaded models
test_loss, test_accuracy = loaded_model.evaluate(test_features, test_labels)

model.save('/content/drive/MyDrive/Capstone/Model/model.h5')

# tflite converter and the optimizations
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]

# Converts model to .tflite format
tfmodel = converter.convert()
open('/content/drive/MyDrive/Capstone/Model/model.tflite', 'wb').write(tfmodel)
pickle.dump(model, open('/content/drive/MyDrive/Capstone/Model/model.pkl', 'wb'))

"""# Predict"""

11#entering the user's food choices
karbohidrat = int(input("Masukkan pilihan Karbohidrat: "))
protein = int(input("Masukkan pilihan Protein: "))
sayur = int(input("Masukkan pilihan Sayur: "))
pengolahan = int(input("Masukkan pilihan Pengolahan: "))

#setting up input for prediction
input_data = np.array([[karbohidrat, protein, sayur, pengolahan]])

#making predictions using the model
predicted = np.argmax(model.predict(input_data))

#looking for class-appropriate food
makanan_sesuai_kelas = data[data['Kelas'] == predicted]['Makanan'].tolist()

#displaying a list of suitable foods
if makanan_sesuai_kelas:
    print("Makanan yang sesuai dengan pilihan Anda:")
    for makanan in makanan_sesuai_kelas:
        print(makanan)
else:
    print("Mohon maaf, makanan tidak tersedia.")
